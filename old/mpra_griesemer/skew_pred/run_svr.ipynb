{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20d5284-43a5-4c57-9006-828f0883a2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.pipeline \n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.svm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/data/ouga/home/ag_gagneur/l_vilov/workspace/species-aware-DNA-LM/mpra_griesemer/utils\") \n",
    "\n",
    "from models import *\n",
    "from misc import dotdict\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e82215c-3d72-4985-acbf-fd521ff920d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/s/project/mll/sergey/effect_prediction/MLM/griesemer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62141475-833c-4454-9c27-137e8d7686f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_params = dotdict({})\n",
    "\n",
    "input_params.cell_type = 'HEPG2' #HMEC,HEK293FT,HEPG2,K562,GM12878,SKNSH\n",
    "\n",
    "input_params.model = 'word2vec' #embedding name, can be \"MLM\" \"word2vec\" \"griesemer\" or \"Nmers\" where N is an integer\n",
    "\n",
    "input_params.output_dir = './test' #output folder\n",
    "\n",
    "input_params.N_trials = 1000 #number of optuna trials\n",
    "input_params.n_jobs = 8\n",
    "\n",
    "input_params.N_splits = 10 #number of GroupShuffleSplits\n",
    "input_params.N_CVsplits = 5 #number of CV splits for hyperparameter search\n",
    "input_params.seed = 1 #seed fot GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b876caad-6e6f-46b4-a7f4-a24323af5bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpra_df = pd.read_csv(data_dir + 'mpra_df.tsv', sep='\\t') #sequence info\n",
    "\n",
    "mpra_df['tag'] = mpra_df.oligo_id.apply(lambda x:'ref' if 'ref' in x else 'alt')\n",
    "\n",
    "mlm_embeddings = np.load(data_dir + \"embeddings/seq_len_5000/embeddings.npy\") #masked language model embeddings\n",
    "\n",
    "#Data Cleaning\n",
    "# Take only SNP mutations\n",
    "# Remove nan values in Expression column\n",
    "\n",
    "is_snp = mpra_df.ref_allele.str.len() == mpra_df.alt_allele.str.len()\n",
    "\n",
    "flt = mpra_df[f'log2FoldChange_Skew_{input_params.cell_type}'].isna()  | (~is_snp) | (mpra_df.stop_codon_dist>5000) #| mpra_df.oligo_id.str.contains('_ref$')\n",
    "\n",
    "mpra_df = mpra_df[~flt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cceb1dd-9621-45a6-8e4a-170c7f3d4542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Expression column to float\n",
    "mpra_df['Expression'] = mpra_df[f'log2FoldChange_Skew_{input_params.cell_type}']\n",
    "\n",
    "assert all(mpra_df.loc[mpra_df.tag=='ref','mpra_variant_id'].values==\n",
    "         mpra_df.loc[mpra_df.tag=='alt','mpra_variant_id'].values)\n",
    "    \n",
    "mpra_df.Expression = mpra_df.Expression.apply(lambda x:x.replace(',','.') if type(x)==str else x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01a236c0-2c09-4bdb-912d-408ceea1bd76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enformer_dir = data_dir + 'enformer/predictions/'\n",
    "\n",
    "data = {}\n",
    "\n",
    "for pickle_file in os.listdir(enformer_dir):\n",
    "    with open(enformer_dir+pickle_file,'rb') as f:\n",
    "        data = data|pickle.load(f)\n",
    "        \n",
    "enformer_df = pd.DataFrame(data).T\n",
    "\n",
    "idx = mpra_df.set_index(['mpra_variant_id','tag']).index\n",
    "\n",
    "enformer_df = enformer_df.loc[idx].swaplevel() #get variants in exactly the same order as in mpra_df\n",
    "\n",
    "enformer_log2fc = np.log2(enformer_df.loc['alt']/enformer_df.loc['ref']) #log2fc for all targets\n",
    "\n",
    "enformer_log2fc = enformer_log2fc.fillna(enformer_log2fc.median())\n",
    "\n",
    "assert all(enformer_log2fc.index==mpra_df[mpra_df.tag=='alt'].mpra_variant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ca9f16-a4a4-49fd-a1a5-6a32e1b43a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(mpra_df):\n",
    "\n",
    "    if input_params.model=='MLM':\n",
    "\n",
    "        X = mlm_embeddings[mpra_df.index]\n",
    "\n",
    "    elif 'mers' in input_params.model:\n",
    "\n",
    "        k = int(input_params.model[0])\n",
    "\n",
    "        kmerizer = Kmerizer(k=k)\n",
    "        X = np.stack(mpra_df.seq.apply(lambda x: kmerizer.kmerize(x))) \n",
    "\n",
    "    elif input_params.model=='word2vec':\n",
    "\n",
    "        X = word2vec_model(mpra_df)\n",
    "\n",
    "    elif input_params.model=='griesemer':\n",
    "\n",
    "        X = minseq_model(mpra_df)\n",
    "\n",
    "    X = np.hstack((X,np.expand_dims(mpra_df.min_free_energy.values,axis=1)))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38d045cc-18f2-4d7a-8c81-8c673d18a064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_enformer_matrix(model):\n",
    " \n",
    "    dnase_all_idx = np.array(np.arange(0,674)) \n",
    "\n",
    "    cage_all_idx = np.array(np.arange(4675,5313)) \n",
    "\n",
    "    chipseq_all_idx = np.array(np.arange(674,4675)) \n",
    "\n",
    "    if model == 'enformer_all_targets':\n",
    "        \n",
    "        X = enformer_log2fc.values\n",
    "        \n",
    "    elif model == 'enformer_summary':\n",
    "        \n",
    "        X = np.vstack((enformer_log2fc[dnase_all_idx].mean(axis=1),\n",
    "                       enformer_log2fc[cage_all_idx].mean(axis=1),\n",
    "                         enformer_log2fc[cage_all_idx].mean(axis=1))).T\n",
    "        \n",
    "    X = np.hstack((X,\n",
    "                   np.expand_dims(mpra_df[mpra_df.tag=='alt'].min_free_energy.values,axis=1),\n",
    "                    np.expand_dims(mpra_df[mpra_df.tag=='ref'].min_free_energy.values,axis=1)))\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db65324c-4d25-492e-a4f5-767e00d1f4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not 'enformer' in input_params.model:\n",
    "    \n",
    "    X_ref = get_embeddings(mpra_df[mpra_df.tag=='ref'])\n",
    "    X_alt = get_embeddings(mpra_df[mpra_df.tag=='alt'])\n",
    "\n",
    "    X = np.hstack((X_ref,X_alt))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    X = get_enformer_matrix(input_params.model)\n",
    "\n",
    "y = mpra_df.loc[mpra_df.tag=='alt', 'Expression'].values\n",
    "groups = mpra_df.loc[mpra_df.tag=='alt', 'group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fc5beaf-d2ee-45ad-a40f-309609edff82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hpp_search(X,y,groups,cv_splits = 5):\n",
    "    \n",
    "    '''\n",
    "    Perform Hyperparameter Search using OPTUNA Bayesian Optimisation strategy\n",
    "    \n",
    "    The bets hyperparameters should maximize coefficient of determination (R2)\n",
    "    \n",
    "    The hyperparameter range should first be adjused with grid search to make the BO algorithm converge in reasonable time\n",
    "    '''\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        C = trial.suggest_float(\"C\", 1e-5, 1e2, log=True)\n",
    "        epsilon = trial.suggest_float(\"epsilon\", 1e-5, 1, log=True)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1e-5, 1, log=True)\n",
    "\n",
    "        clf = sklearn.svm.SVR(C=C, epsilon=epsilon, gamma=gamma)\n",
    "\n",
    "        pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),clf)\n",
    "\n",
    "        cv_score = sklearn.model_selection.cross_val_score(pipe, X, y, groups=groups, \n",
    "                     cv = sklearn.model_selection.GroupKFold(n_splits = cv_splits), scoring = 'r2', n_jobs = -1)\n",
    "        \n",
    "        av_score = cv_score.mean()\n",
    "        \n",
    "        return av_score\n",
    "    \n",
    "    study = optuna.create_study(direction = \"maximize\")\n",
    "\n",
    "    study.optimize(objective, n_trials = input_params.N_trials)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d37ae7-fe28-4424-806b-56f76c702cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parallel\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "gss = sklearn.model_selection.GroupShuffleSplit(n_splits=input_params.N_splits, train_size=.9, random_state = input_params.seed) \n",
    "\n",
    "train_idx, test_idx = next(iter(gss.split(X, y, groups)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[train_idx,:],X[test_idx,:],y[train_idx],y[test_idx] #first split\n",
    "\n",
    "#best_hpp = hpp_search(X_train,y_train,groups[train_idx],cv_splits = input_params.N_CVsplits) #get optimal hyperparameters\n",
    "\n",
    "best_hpp = {'C': 0.03943153578419499, 'epsilon': 0.0712140417882623, 'gamma': 0.000232694021502066}\n",
    "\n",
    "def apply_SVR(args):\n",
    "    \n",
    "    train_idx, test_idx = args\n",
    "\n",
    "    pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),\n",
    "                                              sklearn.svm.SVR(**best_hpp))\n",
    "    \n",
    "    #pipe = sklearn.ensemble.RandomForestRegressor(n_jobs=-1, n_estimators=500)\n",
    "    \n",
    "    pipe.fit(X[train_idx,:],y[train_idx])  \n",
    "    \n",
    "    y_pred = np.full_like(y,np.NaN)\n",
    "    \n",
    "    y_pred[test_idx] = pipe.predict(X[test_idx,:])  \n",
    "    \n",
    "    r2 = sklearn.metrics.r2_score(y[test_idx], y_pred[test_idx])\n",
    "    \n",
    "    print('done')\n",
    "\n",
    "    return y_pred, r2\n",
    " \n",
    "def run_pool():\n",
    "    \n",
    "    all_res = []\n",
    "    \n",
    "    pool = Pool(processes=input_params.n_jobs,maxtasksperchild=5)\n",
    "\n",
    "    #for train_idx, test_idx in gss.split(X,y,groups):\n",
    "    #    pool.apply_async(apply_SVR,args =  (train_idx,test_idx), callback=log_result)\n",
    "    \n",
    "    for res in pool.imap(apply_SVR,gss.split(X,y,groups)):\n",
    "        all_res.append(res)\n",
    "     \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return all_res\n",
    "\n",
    "print('running parallel')\n",
    "\n",
    "all_res = run_pool()\n",
    "\n",
    "preds, scores = zip(*all_res)\n",
    "\n",
    "cv_res = np.vstack(preds)\n",
    "\n",
    "cv_scores = pd.DataFrame({'round':range(input_params.N_splits),'scores':scores}|best_hpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dcb2840-9b1a-45bc-a866-03929ec8abc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>scores</th>\n",
       "      <th>C</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.018462</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.067523</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.060643</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.099096</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.016646</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.134746</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round    scores         C   epsilon     gamma\n",
       "0      0  0.007261  0.039432  0.071214  0.000233\n",
       "1      1  0.028734  0.039432  0.071214  0.000233\n",
       "2      2 -0.018462  0.039432  0.071214  0.000233\n",
       "3      3 -0.067523  0.039432  0.071214  0.000233\n",
       "4      4 -0.060643  0.039432  0.071214  0.000233\n",
       "5      5 -0.099096  0.039432  0.071214  0.000233\n",
       "6      6 -0.016646  0.039432  0.071214  0.000233\n",
       "7      7  0.038696  0.039432  0.071214  0.000233\n",
       "8      8 -0.046875  0.039432  0.071214  0.000233\n",
       "9      9 -0.134746  0.039432  0.071214  0.000233"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33c8ba-5c3a-49b2-ac80-ee3598ad66d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(input_params.output_dir, exist_ok=True) #make output dir\n",
    "\n",
    "cv_scores.to_csv(input_params.output_dir + '/cv_scores.tsv', sep='\\t', index=None) #save scores\n",
    "\n",
    "with open(input_params.output_dir + '/cv_res.npy', 'wb') as f:\n",
    "    np.save(f, cv_res) #save predictions at each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ced1b3-3076-4177-8556-e54c2069ce78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-svilov-spade]",
   "language": "python",
   "name": "conda-env-miniconda3-svilov-spade-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
